{"cells":[{"cell_type":"markdown","id":"c86a5252","metadata":{"id":"c86a5252"},"source":["##### 1. Utility Functions and Imports"]},{"cell_type":"code","execution_count":null,"id":"CHePgcM0GH7C","metadata":{"id":"CHePgcM0GH7C"},"outputs":[],"source":["import os\n","import sys\n","import random\n","import shutil\n","from collections import Counter\n","import tensorflow as tf\n","from datetime import datetime\n","from pathlib import Path\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, models, optimizers, callbacks\n","from tensorflow.keras.applications import EfficientNetV2B0, InceptionV3\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score, precision_score, recall_score\n","from keras.saving import register_keras_serializable\n","from tensorflow.keras.applications import vgg16, resnet50, inception_v3"]},{"cell_type":"code","execution_count":null,"id":"932351b5","metadata":{"id":"932351b5"},"outputs":[],"source":["!pip install -q scikit-learn\n","\n","#############\n","# Constants\n","#############\n","\n","SEED=123\n","IMAGE_SIZE = (224, 224)\n","BATCH_SIZE = 32\n","NUM_CLASSES = 3\n","CLASS_NAMES = ['brain_glioma', 'brain_menin', 'brain_tumor']\n","\n","# Update to True to use Drive for data storage\n","USE_DRIVE = False\n","\n","#############\n","# Colab check\n","#############\n","\n","def is_colab():\n","    return 'google.colab' in sys.modules\n","\n","#############\n","# EDA\n","#############\n","\n","def plot_raw_dataset(raw_data_dir):\n","\n","    class_counts = {}\n","\n","    for class_name in sorted(os.listdir(raw_data_dir)):\n","        class_path = os.path.join(raw_data_dir, class_name)\n","        if os.path.isdir(class_path):\n","            num_images = len([\n","                f for f in os.listdir(class_path)\n","                if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n","            ])\n","            class_counts[class_name] = num_images\n","\n","    classes = list(class_counts.keys())\n","    counts = list(class_counts.values())\n","\n","    plt.figure(figsize=(10, 6))\n","    ax = sns.barplot(x=classes, y=counts, palette=[\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"])\n","    plt.title(\"Raw Dataset Class Distribution\", fontsize=16)\n","    plt.xlabel(\"Number of Images\")\n","    plt.ylabel(\"Class\")\n","    for container in ax.containers:\n","        ax.bar_label(container)\n","    plt.tight_layout()\n","    plt.show()\n","\n","def analyze_datasets(dataset, dataset_name=\"Dataset\", class_names=None):\n","\n","    print(f\"{dataset_name} Analysis\")\n","    print(\"=\"*50)\n","\n","    total_samples = 0\n","    class_counts = Counter()\n","    all_labels = []\n","\n","    for batch_images, batch_labels in dataset:\n","        batch_size = tf.shape(batch_images)[0].numpy()\n","        total_samples += batch_size\n","\n","        if len(batch_labels.shape) > 1:\n","            batch_indices = tf.argmax(batch_labels, axis=1).numpy()\n","        else:\n","            batch_indices = batch_labels.numpy()\n","\n","        all_labels.extend(batch_indices)\n","\n","        for label in batch_indices:\n","            class_counts[int(label)] += 1\n","\n","    all_labels = np.array(all_labels)\n","\n","    return {\n","        'total_samples': total_samples,\n","        'class_counts': dict(class_counts),\n","        'all_labels': all_labels,\n","        'class_names': class_names\n","    }\n","\n","def plot_class_distribution(stats, title=\"Class Distribution\"):\n","\n","    class_counts = stats['class_counts']\n","    class_names = stats['class_names']\n","\n","    classes = list(class_counts.keys())\n","    counts = list(class_counts.values())\n","\n","    if class_names:\n","        labels = [class_names[i] if i < len(class_names) else f\"Class {i}\" for i in classes]\n","    else:\n","        labels = [f\"Class {i}\" for i in classes]\n","\n","    plt.figure(figsize=(10, 6))\n","    bars = plt.bar(labels, counts, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'][:len(classes)])\n","\n","    for bar, count in zip(bars, counts):\n","        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01,\n","                f'{count:,}', ha='center', va='bottom', fontweight='bold')\n","\n","    plt.title(title, fontsize=16, fontweight='bold')\n","    plt.xlabel('Classes', fontsize=12)\n","    plt.ylabel('Number of Samples', fontsize=12)\n","    plt.xticks(rotation=45)\n","    plt.grid(axis='y', alpha=0.3)\n","    plt.tight_layout()\n","    plt.show()\n","\n","def show_dataset_samples():\n","\n","    train_dir = os.path.join(DATA_DIR, \"Training\")\n","    classes = CLASS_NAMES\n","\n","    plt.figure(figsize=(8, 9))\n","\n","    for i in range(3):\n","        for j in range(2):\n","            plt.subplot(3, 2, i*2 + j + 1)\n","            plt.xticks([])\n","            plt.yticks([])\n","\n","            class_path = os.path.join(train_dir, classes[i])\n","            files = sorted([f for f in os.listdir(class_path)\n","                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n","\n","            if j < len(files):\n","                img_path = os.path.join(class_path, files[j])\n","                img = plt.imread(img_path)\n","                plt.imshow(img)\n","                plt.xlabel(f\"{classes[i]}\\n{files[j]}\")\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","#################################################################\n","# Dataset preprocessing functions\n","#################################################################\n","\n","def split_dataset(input_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=SEED):\n","    random.seed(seed)\n","    input_dir = Path(input_dir)\n","    output_dir = Path(output_dir)\n","\n","    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, \"Ratios must sum to 1.\"\n","\n","    classes = [d.name for d in input_dir.iterdir() if d.is_dir()]\n","\n","    for cls in classes:\n","        class_dir = input_dir / cls\n","        images = sorted(list(class_dir.glob('*')))\n","        random.shuffle(images)\n","\n","        n_total = len(images)\n","        n_train = round(train_ratio * n_total)\n","        n_val = round(val_ratio * n_total)\n","        n_test = n_total - n_train - n_val\n","\n","        splits = {\n","            'Training': images[:n_train],\n","            'Validation': images[n_train:n_train + n_val],\n","            'Testing': images[n_train + n_val:],\n","        }\n","\n","        for split_name, split_files in splits.items():\n","            split_path = output_dir / split_name / cls\n","            split_path.mkdir(parents=True, exist_ok=True)\n","            for f in split_files:\n","                shutil.copy(f, split_path / f.name)\n","\n","    print(\"Dataset successfully split into Training, Validation, and Testing folders.\")\n","\n","\n","def load_images_from_directory(directory, image_size=IMAGE_SIZE):\n","\n","    X = []\n","    y = []\n","    class_names = sorted(os.listdir(directory))\n","\n","    for label in class_names:\n","        class_dir = os.path.join(directory, label)\n","        if not os.path.isdir(class_dir):\n","            continue\n","        for file in os.listdir(class_dir):\n","            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n","                img_path = os.path.join(class_dir, file)\n","                try:\n","                    # img = Image.open(img_path).convert('L')\n","                    img = Image.open(img_path).convert('RGB')\n","                    img = img.resize(image_size)\n","                    X.append(np.array(img))\n","                    y.append(label)\n","                except Exception as e:\n","                    print(f\"Error loading {img_path}: {e}\")\n","\n","    X = np.array(X, dtype='float32') / 255.0\n","    y = np.array(y)\n","\n","    return X, y, class_names\n","\n","\n","def load_dataset_from_splits(base_dir, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, seed=SEED):\n","\n","    X_train, y_train_raw, _ = load_images_from_directory(os.path.join(base_dir, \"Training\"), image_size)\n","    X_val, y_val_raw, _ = load_images_from_directory(os.path.join(base_dir, \"Validation\"), image_size)\n","    X_test, y_test_raw, _ = load_images_from_directory(os.path.join(base_dir, \"Testing\"), image_size)\n","\n","    all_labels = np.concatenate([y_train_raw, y_val_raw, y_test_raw])\n","    label_encoder = LabelEncoder()\n","    label_encoder.fit(all_labels)\n","\n","    y_train = label_encoder.transform(y_train_raw)\n","    y_val = label_encoder.transform(y_val_raw)\n","    y_test = label_encoder.transform(y_test_raw)\n","\n","    assert len(X_train) == len(y_train), \"Mismatch in train X/y\"\n","    assert len(X_val) == len(y_val), \"Mismatch in val X/y\"\n","    assert len(X_test) == len(y_test), \"Mismatch in test X/y\"\n","\n","    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\\\n","        .shuffle(buffer_size=len(X_train), seed=seed)\\\n","        .batch(batch_size)\\\n","        .prefetch(tf.data.AUTOTUNE)\n","\n","    val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\\\n","        .shuffle(buffer_size=len(X_val), seed=seed)\\\n","        .batch(batch_size)\\\n","        .prefetch(tf.data.AUTOTUNE)\n","\n","    test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\\\n","        .batch(batch_size)\\\n","        .prefetch(tf.data.AUTOTUNE)\n","\n","    return train_ds, val_ds, test_ds, label_encoder.classes_\n","\n","\n","#################################################################\n","# Model Plots - Evaluation Metrics\n","#################################################################\n","\n","def evaluate_model(model, test_ds, class_names, model_name=\"Model\"):\n","\n","    y_true = []\n","    y_pred = []\n","\n","    for images, labels in test_ds:\n","        preds = model.predict(images)\n","        y_pred.extend(np.argmax(preds, axis=1))\n","        y_true.extend(labels.numpy())\n","\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    acc = np.mean(y_true == y_pred)\n","    f1 = f1_score(y_true, y_pred, average='weighted')\n","    precision = precision_score(y_true, y_pred, average='weighted')\n","    recall = recall_score(y_true, y_pred, average='weighted')\n","\n","    print(f\"{model_name}\")\n","    print(f\"Accuracy : {acc:.3f}\")\n","    print(f\"F1 Score : {f1:.3f}\")\n","    print(f\"Precision: {precision:.3f}\")\n","    print(f\"Recall   : {recall:.3f}\")\n","\n","    cm = confusion_matrix(y_true, y_pred)\n","    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n","\n","    plt.figure(figsize=(6, 6))\n","    disp.plot(cmap=plt.cm.Blues, values_format=\"d\")\n","    plt.title(f\"Confusion Matrix: {model_name}\")\n","    plt.show()\n","\n","    return acc, f1, precision, recall\n","\n","\n","def plot_training_curves(history, title=\"Model\"):\n","\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history.history['accuracy'], label='Train Acc')\n","    plt.plot(history.history['val_accuracy'], label='Val Acc')\n","    plt.title(f'{title} Accuracy')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history.history['loss'], label='Train Loss')\n","    plt.plot(history.history['val_loss'], label='Val Loss')\n","    plt.title(f'{title} Loss')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"gm6XeZBvYs9a","metadata":{"id":"gm6XeZBvYs9a"},"outputs":[],"source":["#################################################################\n","# Model functions\n","#################################################################\n","\n","def compile_and_fit(model,\n","                    train_data,\n","                    val_data,\n","                    model_name,\n","                    epochs=20,\n","                    lr=1e-4,\n","                    checkpoint_dir='./checkpoints'):\n","\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    ckpt_path = os.path.join(checkpoint_dir, f\"{model_name}_best.h5\")\n","\n","    checkpoint_cb = callbacks.ModelCheckpoint(\n","        filepath=ckpt_path,\n","        monitor=\"val_accuracy\",\n","        mode=\"max\",\n","        save_best_only=True,\n","        verbose=1\n","    )\n","\n","    early_stop_cb = callbacks.EarlyStopping(\n","        monitor=\"val_accuracy\",\n","        patience=5,\n","        mode=\"max\",\n","        restore_best_weights=True\n","    )\n","\n","    reduce_lr_cb = callbacks.ReduceLROnPlateau(\n","        monitor='val_loss',\n","        factor=0.5,\n","        patience=3,\n","        min_delta=1e-3,\n","        min_lr=1e-6,\n","        verbose=1\n","    )\n","\n","    # target labels are integers (not one-hot encoded vectors) - more memory-efficient\n","    model.compile(\n","        optimizer=optimizers.Adam(learning_rate=lr),\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    history = model.fit(\n","        train_data,\n","        validation_data=val_data,\n","        epochs=epochs,\n","        callbacks=[checkpoint_cb, early_stop_cb, reduce_lr_cb]\n","    )\n","\n","    return history, ckpt_path\n","\n","\n","def save_model_summary(model, model_name=\"model\", save_dir=\"./model_summaries\"):\n","\n","    os.makedirs(save_dir, exist_ok=True)\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","    filename = f\"{model_name}_summary_{timestamp}.txt\"\n","    filepath = os.path.join(save_dir, filename)\n","\n","    with open(filepath, \"w\") as f:\n","        model.summary(print_fn=lambda x: f.write(x + \"\\n\"))\n","\n","    print(f\"Model summary saved to: {filepath}\")\n","\n","    return filepath\n"]},{"cell_type":"markdown","id":"926f26de","metadata":{"id":"926f26de"},"source":["##### 2. Setup - Environment check - DataSet split"]},{"cell_type":"code","execution_count":null,"id":"1aa0ea05","metadata":{"id":"1aa0ea05"},"outputs":[],"source":["if is_colab():\n","    print(\"Running in Google Colab\")\n","\n","    !pip install -q kaggle\n","\n","    from google.colab import files\n","    kaggleKey = \"/content/kaggle.json\"\n","    if not os.path.exists(kaggleKey):\n","      key = files.upload()\n","    else:\n","      print(\"Kaggle.json exists\")\n","\n","    !mkdir -p ~/.kaggle\n","    !cp kaggle.json ~/.kaggle/\n","    !chmod 600 ~/.kaggle/kaggle.json\n","\n","    if USE_DRIVE:\n","    # Google Drive paths\n","      print(\"Using google Drive and persistent dataset\")\n","      from google.colab import drive\n","      drive.mount('/content/drive')\n","\n","      RAW_DATA_DIR = \"/content/drive/MyDrive/datasets/brain_tumor_raw/Brain_Cancer raw MRI data/Brain_Cancer\"\n","      DATA_DIR = \"/content/drive/MyDrive/datasets/brain_tumor_split\"\n","      EXTRACT_PATH = \"/content/drive/MyDrive/datasets/brain_tumor_raw\"\n","      MODEL_DIR = \"/content/drive/MyDrive/models\"\n","    else:\n","    # Rutime paths\n","      print(\"Using runtime and non-persistent dataset\")\n","      RAW_DATA_DIR = \"/content/datasets/brain_tumor_raw/Brain_Cancer raw MRI data/Brain_Cancer\"\n","      DATA_DIR = \"/content/datasets/brain_tumor_split\"\n","      EXTRACT_PATH = \"/content/datasets/brain_tumor_raw\"\n","      MODEL_DIR = \"/content/models\"\n","\n","    os.makedirs(DATA_DIR, exist_ok=True)\n","    os.makedirs(MODEL_DIR, exist_ok=True)\n","\n","    # Download dataset from Kaggle if not already done\n","    if not os.path.exists(EXTRACT_PATH):\n","        !kaggle datasets download -d orvile/brain-cancer-mri-dataset\n","        os.makedirs(EXTRACT_PATH, exist_ok=True)\n","        !unzip -q brain-cancer-mri-dataset.zip -d \"$EXTRACT_PATH\"\n","\n","else:\n","    print(\"Running locally on Mac\")\n","    DATA_DIR = \"/Users/thodorischaros/Documents/MSc/datasets/brain_tumor_split\"\n","    MODEL_DIR = \"/Users/thodorischaros/Documents/MSc/AIDL_A02_NeuralNetworksandDeepLearning/final_project/models\"\n","    RAW_DATA_DIR = \"/Users/thodorischaros/Documents/MSc/datasets/Brain_Cancer raw MRI data/Brain_Cancer\"\n","    EXTRACT_PATH = \"/Users/thodorischaros/Documents/MSc/datasets/brain_tumor_raw\""]},{"cell_type":"markdown","id":"bfe2df76","metadata":{"id":"bfe2df76"},"source":["##### 3. Dataset analysis"]},{"cell_type":"code","execution_count":null,"id":"bdfJVVRmrHCe","metadata":{"id":"bdfJVVRmrHCe"},"outputs":[],"source":["# Raw dataset distribution\n","\n","plot_raw_dataset(RAW_DATA_DIR)"]},{"cell_type":"code","execution_count":null,"id":"qI0CFcWjfep9","metadata":{"id":"qI0CFcWjfep9"},"outputs":[],"source":["# Split dataset to train/val/test\n","\n","if not os.path.exists(os.path.join(DATA_DIR, \"Training\")):\n","    split_dataset(RAW_DATA_DIR, DATA_DIR)\n","\n","train_ds, val_ds, test_ds, class_names = load_dataset_from_splits(DATA_DIR)\n","\n","print(\"Images loaded\")\n","print(\"Number of training batches:\", len(train_ds))\n","print(\"Number of validation batches:\", len(val_ds))\n","print(\"Number of test batches:\", len(test_ds))\n","print(\"Classes:\", class_names)"]},{"cell_type":"code","execution_count":null,"id":"fN4aYJ0fVPCG","metadata":{"id":"fN4aYJ0fVPCG"},"outputs":[],"source":["# train/test/val datasets distribution\n","\n","if 'train_ds' in globals():\n","    train_stats = analyze_datasets(train_ds, \"Training Dataset\", CLASS_NAMES)\n","    plot_class_distribution(train_stats, \"Training Set - Class Distribution\")\n","\n","print(\"\\n\" + \"=\"*60)\n","\n","if 'val_ds' in globals():\n","    val_stats = analyze_datasets(val_ds, \"Validation Dataset\", CLASS_NAMES)\n","    plot_class_distribution(val_stats, \"Validation Set - Class Distribution\")\n","\n","print(\"\\n\" + \"=\"*60)\n","\n","if 'test_ds' in globals():\n","    test_stats = analyze_datasets(test_ds, \"Test Dataset\", CLASS_NAMES)\n","    plot_class_distribution(test_stats, \"Test Set - Class Distribution\")"]},{"cell_type":"code","execution_count":null,"id":"rS5XadoDHr58","metadata":{"id":"rS5XadoDHr58"},"outputs":[],"source":["# sample images from dataset\n","\n","show_dataset_samples()"]},{"cell_type":"code","execution_count":null,"id":"v1iLcMisDr2M","metadata":{"id":"v1iLcMisDr2M"},"outputs":[],"source":["# sample from train dataset to check that all classes were loaded and shuffled\n","\n","for images, labels in train_ds.take(1):\n","    print(\"Image shape:\", images.shape)\n","    print(\"Image range:\", images.numpy().min(), \"to\", images.numpy().max())\n","    print(\"Labels:\", labels.numpy()[:10])\n","    print(\"Unique labels:\", np.unique(labels.numpy()))"]},{"cell_type":"markdown","id":"81213bf0","metadata":{"id":"81213bf0"},"source":["##### 4. Custom CNNs"]},{"cell_type":"markdown","id":"8gyYUfAUMNIv","metadata":{"id":"8gyYUfAUMNIv"},"source":["CNN 1\n","\n","\n","*  CNN5 with different lr and epochs\n","\n"]},{"cell_type":"code","execution_count":null,"id":"tJz1MApoG98v","metadata":{"id":"tJz1MApoG98v"},"outputs":[],"source":["def build_custom_cnn_1(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    model = models.Sequential([\n","\n","        layers.Input(shape=input_shape),\n","\n","        # Block 1\n","        layers.Conv2D(32, 3, activation='relu', padding='same'),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(32, 3, activation='relu', padding='same'),\n","        layers.MaxPooling2D(),\n","        layers.Dropout(0.3),\n","\n","        # Block 2\n","        layers.Conv2D(64, 3, activation='relu', padding='same'),\n","        layers.BatchNormalization(),\n","        layers.Conv2D(64, 3, activation='relu', padding='same'),\n","        layers.MaxPooling2D(),\n","        layers.Dropout(0.3),\n","\n","        # Classifier Head\n","        layers.Flatten(),\n","        layers.Dense(128, activation='relu'),\n","        layers.BatchNormalization(),\n","        layers.Dropout(0.5),\n","\n","        layers.Dense(num_classes, activation='softmax')\n","    ])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"F-Ui_sFZQy4N","metadata":{"id":"F-Ui_sFZQy4N"},"outputs":[],"source":["cnn1 = build_custom_cnn_1()\n","history1, best_cnn1_model_path = compile_and_fit(cnn1, train_ds, val_ds,\n","                                            model_name=\"CNN_1\",\n","                                            epochs=40, lr=1e-3)"]},{"cell_type":"code","execution_count":null,"id":"HFjFMVa0wvhe","metadata":{"collapsed":true,"id":"HFjFMVa0wvhe"},"outputs":[],"source":["best_cnn1_model = keras.models.load_model(best_cnn1_model_path)\n","evaluate_model(best_cnn1_model, test_ds, class_names, model_name=\"CNN1\")"]},{"cell_type":"code","execution_count":null,"id":"_C1iRMucJJg0","metadata":{"id":"_C1iRMucJJg0"},"outputs":[],"source":["plot_training_curves(history1, title='CNN_1')"]},{"cell_type":"code","execution_count":null,"id":"PEHBK-7GuTJ7","metadata":{"id":"PEHBK-7GuTJ7"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# cnn1.save(os.path.join(MODEL_DIR, f\"cnn1_{timestamp}.h5\"))\n","# save_model_summary(best_cnn1_model, model_name=\"CNN1\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"code","execution_count":null,"id":"TpTlmoyPi7lM","metadata":{"id":"TpTlmoyPi7lM"},"outputs":[],"source":["cnn5 = build_custom_cnn_1()\n","history5, best_cnn5_model_path = compile_and_fit(cnn5, train_ds, val_ds,\n","                                            model_name=\"CNN_5\",\n","                                            epochs=40, lr=1e-3)\n","\n","best_cnn5_model = keras.models.load_model(best_cnn5_model_path)\n","evaluate_model(best_cnn5_model, test_ds, class_names, model_name=\"CNN5\")\n","\n","plot_training_curves(history5, title='CNN_5')"]},{"cell_type":"code","execution_count":null,"id":"ORPG1p3BLHv1","metadata":{"id":"ORPG1p3BLHv1"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# cnn5.save(os.path.join(MODEL_DIR, f\"cnn5_{timestamp}.h5\"))\n","# save_model_summary(best_cnn1_model, model_name=\"CNN5\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"code","execution_count":null,"id":"i_CwJQPCjDbc","metadata":{"id":"i_CwJQPCjDbc"},"outputs":[],"source":["cnn4 = build_custom_cnn_1()\n","history4, best_cnn4_model_path = compile_and_fit(cnn4, train_ds, val_ds,\n","                                            model_name=\"CNN_4\",\n","                                            epochs=40, lr=1e-5)\n","\n","best_cnn4_model = keras.models.load_model(best_cnn4_model_path)\n","evaluate_model(best_cnn4_model, test_ds, class_names, model_name=\"CNN4\")\n","\n","plot_training_curves(history4, title='CNN_4')"]},{"cell_type":"code","execution_count":null,"id":"4QFUFashLJJA","metadata":{"id":"4QFUFashLJJA"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# cnn4.save(os.path.join(MODEL_DIR, f\"cnn4_{timestamp}.h5\"))\n","# save_model_summary(best_cnn4_model, model_name=\"CNN4\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"zQPuhfONMP2p","metadata":{"id":"zQPuhfONMP2p"},"source":["CNN 2"]},{"cell_type":"code","execution_count":null,"id":"jJ3zNPlBQtTD","metadata":{"id":"jJ3zNPlBQtTD"},"outputs":[],"source":["def build_custom_cnn_2(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(shape=input_shape)\n","\n","    # Block 1\n","    x = layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)\n","    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    # Block 2\n","    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Dropout(0.3)(x)\n","    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(128, activation='relu')(x)\n","    x = layers.Dropout(0.2)(x)\n","\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    return models.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"id":"8IFi8HAJQ2Hu","metadata":{"id":"8IFi8HAJQ2Hu"},"outputs":[],"source":["cnn2 = build_custom_cnn_2()\n","history2, best_cnn2_model_path = compile_and_fit(cnn2, train_ds, val_ds,\n","                           model_name=\"CNN_2\",\n","                           epochs=30, lr=1e-5)"]},{"cell_type":"code","execution_count":null,"id":"IAV59UlV0eaY","metadata":{"id":"IAV59UlV0eaY"},"outputs":[],"source":["best_cnn2_model = keras.models.load_model(best_cnn2_model_path)\n","evaluate_model(best_cnn2_model, test_ds, class_names, model_name=\"CNN2\")"]},{"cell_type":"code","execution_count":null,"id":"SXOzm7fxMJlS","metadata":{"id":"SXOzm7fxMJlS"},"outputs":[],"source":["plot_training_curves(history2, title='CNN_2')"]},{"cell_type":"code","execution_count":null,"id":"Iy-Ilwhd0g0e","metadata":{"id":"Iy-Ilwhd0g0e"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# cnn2.save(os.path.join(MODEL_DIR, f\"cnn2_{timestamp}.h5\"))\n","# save_model_summary(best_cnn2_model, model_name=\"CNN2\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"zBqbEfxYMRrg","metadata":{"id":"zBqbEfxYMRrg"},"source":["CNN 3"]},{"cell_type":"code","execution_count":null,"id":"fuK_YG7FQvgx","metadata":{"id":"fuK_YG7FQvgx"},"outputs":[],"source":["def build_custom_cnn_3(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(shape=input_shape)\n","\n","    # Block 1\n","    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    # Block 2\n","    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    # Block 3\n","    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.MaxPooling2D()(x)\n","    x = layers.Dropout(0.4)(x)\n","\n","    # Classifier Head\n","    x = layers.GlobalAveragePooling2D()(x)\n","    x = layers.Dense(128, activation='relu')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dropout(0.5)(x)\n","\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    return models.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"id":"D7OgWyMeQ5_1","metadata":{"id":"D7OgWyMeQ5_1"},"outputs":[],"source":["cnn3 = build_custom_cnn_3()\n","history3, best_cnn3_model_path = compile_and_fit(cnn3, train_ds, val_ds,\n","                           model_name=\"CNN_3\",\n","                           epochs=30, lr=1e-3)"]},{"cell_type":"code","execution_count":null,"id":"1F4SYDFw1nVA","metadata":{"id":"1F4SYDFw1nVA"},"outputs":[],"source":["best_cnn3_model = keras.models.load_model(best_cnn3_model_path)\n","evaluate_model(best_cnn3_model, test_ds, class_names, model_name=\"CNN3\")"]},{"cell_type":"code","execution_count":null,"id":"mnpRo-aeMFDe","metadata":{"id":"mnpRo-aeMFDe"},"outputs":[],"source":["plot_training_curves(history3, title='CNN_3')"]},{"cell_type":"code","execution_count":null,"id":"cKuiT1YN1tn2","metadata":{"id":"cKuiT1YN1tn2"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# cnn3.save(os.path.join(MODEL_DIR, f\"cnn3_{timestamp}.h5\"))\n","# save_model_summary(best_cnn3_model, model_name=\"CNN3\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"6cv_nAhGdnih","metadata":{"id":"6cv_nAhGdnih"},"source":["CNN 6"]},{"cell_type":"code","execution_count":null,"id":"yKSiFwixdmrz","metadata":{"id":"yKSiFwixdmrz"},"outputs":[],"source":["def build_custom_cnn_6(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(shape=input_shape)\n","\n","    # Block 1\n","    x = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D(2)(x)\n","    x = layers.Dropout(0.4)(x)\n","\n","    # Block 2\n","    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D(2)(x)\n","    x = layers.Dropout(0.4)(x)\n","\n","    # Block 3\n","    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Conv2D(256, 3, activation='relu', padding='same')(x)\n","    x = layers.MaxPooling2D(2)(x)\n","    x = layers.Dropout(0.5)(x)\n","\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(1024, activation='relu')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dropout(0.6)(x)\n","\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    return models.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"id":"U4PRvGOkipDs","metadata":{"id":"U4PRvGOkipDs"},"outputs":[],"source":["cnn6 = build_custom_cnn_6()\n","history6, best_cnn6_model_path = compile_and_fit(cnn6, train_ds, val_ds,\n","                           model_name=\"CNN_6\",\n","                           epochs=30, lr=1e-3)"]},{"cell_type":"code","execution_count":null,"id":"t9ue1tkqiuW2","metadata":{"id":"t9ue1tkqiuW2"},"outputs":[],"source":["best_cnn6_model = keras.models.load_model(best_cnn6_model_path)\n","evaluate_model(best_cnn6_model, test_ds, class_names, model_name=\"CNN6\")"]},{"cell_type":"code","execution_count":null,"id":"DBAvL-idiyIJ","metadata":{"id":"DBAvL-idiyIJ"},"outputs":[],"source":["plot_training_curves(history6, title='CNN_6')"]},{"cell_type":"code","execution_count":null,"id":"r8CE-ie8i1tH","metadata":{"id":"r8CE-ie8i1tH"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# cnn6.save(os.path.join(MODEL_DIR, f\"cnn6_{timestamp}.h5\"))\n","# save_model_summary(best_cnn6_model, model_name=\"CNN6\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"9y9hU-pwWkSF","metadata":{"id":"9y9hU-pwWkSF"},"source":["Multi Branch CNN"]},{"cell_type":"code","execution_count":null,"id":"jV85SwMPWexs","metadata":{"id":"jV85SwMPWexs"},"outputs":[],"source":["def build_multibranch_cnn(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(shape=input_shape)\n","\n","    # Branch 1: Fine details (small filters)\n","    branch1 = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n","    branch1 = layers.Conv2D(32, 3, activation='relu', padding='same')(branch1)\n","    branch1 = layers.MaxPooling2D(2)(branch1)\n","    branch1 = layers.Conv2D(64, 3, activation='relu', padding='same')(branch1)\n","    branch1 = layers.MaxPooling2D(2)(branch1)\n","    branch1 = layers.GlobalAveragePooling2D()(branch1)\n","\n","    # Branch 2: Coarse features (larger filters)\n","    branch2 = layers.Conv2D(32, 7, activation='relu', padding='same')(inputs)\n","    branch2 = layers.Conv2D(32, 5, activation='relu', padding='same')(branch2)\n","    branch2 = layers.MaxPooling2D(2)(branch2)\n","    branch2 = layers.Conv2D(64, 5, activation='relu', padding='same')(branch2)\n","    branch2 = layers.MaxPooling2D(2)(branch2)\n","    branch2 = layers.GlobalAveragePooling2D()(branch2)\n","\n","    # Branch 3: Edge detection\n","    branch3 = layers.Conv2D(16, 1, activation='relu', padding='same')(inputs)\n","    branch3 = layers.Conv2D(32, 3, activation='relu', padding='same')(branch3)\n","    branch3 = layers.Conv2D(32, 3, activation='relu', padding='same')(branch3)\n","    branch3 = layers.MaxPooling2D(4)(branch3)\n","    branch3 = layers.Conv2D(64, 3, activation='relu', padding='same')(branch3)\n","    branch3 = layers.GlobalAveragePooling2D()(branch3)\n","\n","    # Combine all branches\n","    combined = layers.Concatenate()([branch1, branch2, branch3])\n","\n","    # Final classification\n","    x = layers.Dense(256, activation='relu')(combined)\n","    x = layers.Dropout(0.5)(x)\n","    x = layers.Dense(128, activation='relu')(x)\n","    x = layers.Dropout(0.3)(x)\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    return models.Model(inputs, outputs, name='MultiBranch_CNN')"]},{"cell_type":"code","execution_count":null,"id":"5r-CCq32Jw43","metadata":{"id":"5r-CCq32Jw43"},"outputs":[],"source":["build_multibranch_cnn = build_multibranch_cnn()\n","build_multibranch_cnn_history, build_multibranch_cnn_model_path = compile_and_fit(build_multibranch_cnn, train_ds, val_ds,\n","                                            model_name=\"build_multibranch_cnn\",\n","                                            epochs=30, lr=1e-3)\n","\n","best_build_multibranch_cnn = keras.models.load_model(build_multibranch_cnn_model_path)\n","evaluate_model(build_multibranch_cnn, test_ds, class_names, model_name=\"build_multibranch_cnn\")\n","\n","plot_training_curves(build_multibranch_cnn_history, title='build_multibranch_cnn')"]},{"cell_type":"code","execution_count":null,"id":"Agunf4OVQ8bG","metadata":{"id":"Agunf4OVQ8bG"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# build_multibranch_cnn.save(os.path.join(MODEL_DIR, f\"multibranch_cnn_{timestamp}.h5\"))\n","# save_model_summary(best_build_multibranch_cnn, model_name=\"multibranch_cnn\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"3dZK_cpNGNoM","metadata":{"id":"3dZK_cpNGNoM"},"source":["Multi Scale CNN"]},{"cell_type":"code","execution_count":null,"id":"Fa4fEUt9I19z","metadata":{"id":"Fa4fEUt9I19z"},"outputs":[],"source":["def build_multiscale_cnn(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(shape=input_shape)\n","\n","    def inner_block(x, filters):\n","        # 1x1 conv\n","        branch1 = layers.Conv2D(filters//4, 1, activation='relu', padding='same')(x)\n","\n","        # 1x1 -> 3x3 conv\n","        branch2 = layers.Conv2D(filters//4, 1, activation='relu', padding='same')(x)\n","        branch2 = layers.Conv2D(filters//4, 3, activation='relu', padding='same')(branch2)\n","\n","        # 1x1 -> 5x5 conv (replaced with two 3x3 for efficiency)\n","        branch3 = layers.Conv2D(filters//4, 1, activation='relu', padding='same')(x)\n","        branch3 = layers.Conv2D(filters//4, 3, activation='relu', padding='same')(branch3)\n","        branch3 = layers.Conv2D(filters//4, 3, activation='relu', padding='same')(branch3)\n","\n","        # MaxPool -> 1x1 conv\n","        branch4 = layers.MaxPooling2D(3, strides=1, padding='same')(x)\n","        branch4 = layers.Conv2D(filters//4, 1, activation='relu', padding='same')(branch4)\n","\n","        # Concatenate all branches\n","        return layers.Concatenate()([branch1, branch2, branch3, branch4])\n","\n","    # Initial conv\n","    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n","    x = layers.BatchNormalization()(x)\n","\n","    # Inner blocks\n","    x = inner_block(x, 64)\n","    x = layers.MaxPooling2D(2)(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    x = inner_block(x, 128)\n","    x = layers.MaxPooling2D(2)(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    x = inner_block(x, 256)\n","    x = layers.GlobalAveragePooling2D()(x)\n","\n","    # Classification head\n","    x = layers.Dense(128, activation='relu')(x)\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    return models.Model(inputs, outputs, name='MultiScale_CNN')"]},{"cell_type":"code","execution_count":null,"id":"L1J2vkY4JRfB","metadata":{"id":"L1J2vkY4JRfB"},"outputs":[],"source":["build_multiscale_cnn = build_multiscale_cnn()\n","build_multiscale_cnn_history, build_multiscale_cnn_model_path = compile_and_fit(build_multiscale_cnn, train_ds, val_ds,\n","                                            model_name=\"build_multiscale_cnn\",\n","                                            epochs=20, lr=1e-4)\n","\n","best_build_multiscale_cnn = keras.models.load_model(build_multiscale_cnn_model_path)\n","evaluate_model(best_build_multiscale_cnn, test_ds, class_names, model_name=\"build_multiscale_cnn\")\n","\n","plot_training_curves(build_multiscale_cnn_history, title='build_multiscale_cnn')"]},{"cell_type":"code","execution_count":null,"id":"qCq8ZI9cQ8FS","metadata":{"id":"qCq8ZI9cQ8FS"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# build_multiscale_cnn.save(os.path.join(MODEL_DIR, f\"multiscale_cnn_{timestamp}.h5\"))\n","# save_model_summary(best_build_multiscale_cnn, model_name=\"multiscale_cnn\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"ae9f77f6","metadata":{"id":"ae9f77f6"},"source":["##### 5. Transfer Learning"]},{"cell_type":"code","source":["@register_keras_serializable(package=\"preproc\")\n","def vgg16_preproc(x): return vgg16.preprocess_input(x)\n","\n","@register_keras_serializable(package=\"preproc\")\n","def resnet50_preproc(x): return resnet50.preprocess_input(x)\n","\n","@register_keras_serializable(package=\"preproc\")\n","def inceptionv3_preproc(x): return inception_v3.preprocess_input(x)"],"metadata":{"id":"pRsn3m6l1kGZ"},"id":"pRsn3m6l1kGZ","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"HG0cO1HHTUfQ","metadata":{"id":"HG0cO1HHTUfQ"},"source":["VGG 16"]},{"cell_type":"code","execution_count":null,"id":"324276da","metadata":{"id":"324276da"},"outputs":[],"source":["def build_vgg16(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(shape=input_shape)\n","\n","    x = layers.Rescaling(255.0, name=\"to_255\")(inputs)\n","    x = layers.Lambda(vgg16_preproc, name=\"vgg16_prep\")(x)\n","\n","    base = keras.applications.VGG16(include_top=False,\n","                                    input_shape=input_shape,\n","                                    weights='imagenet')\n","    base.trainable = False\n","\n","    x = layers.GlobalAveragePooling2D()(base.output)\n","    x = layers.Dense(256,activation='relu')(x)\n","    outputs = layers.Dense(num_classes,activation='softmax')(x)\n","\n","    return models.Model(base.input, outputs)"]},{"cell_type":"code","execution_count":null,"id":"pbv-fR_XQ_Qh","metadata":{"id":"pbv-fR_XQ_Qh"},"outputs":[],"source":["vgg16_model = build_vgg16()\n","history_vgg16, best_vgg16_model_path = compile_and_fit(vgg16_model, train_ds, val_ds,\n","                              model_name=\"VGG16_finetune\",\n","                              epochs=20, lr=1e-4)"]},{"cell_type":"code","execution_count":null,"id":"eoBHNpSLoILA","metadata":{"id":"eoBHNpSLoILA"},"outputs":[],"source":["best_vgg16_model = keras.models.load_model(best_vgg16_model_path)\n","evaluate_model(best_vgg16_model, test_ds, class_names, model_name=\"VGG16\")"]},{"cell_type":"code","execution_count":null,"id":"KPBvEzAaoIjf","metadata":{"id":"KPBvEzAaoIjf"},"outputs":[],"source":["plot_training_curves(history_vgg16, title='VGG16')"]},{"cell_type":"code","execution_count":null,"id":"17fY8jqhoCOT","metadata":{"id":"17fY8jqhoCOT"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# vgg16_model.save(os.path.join(MODEL_DIR, f\"vgg16_{timestamp}.h5\"))\n","# save_model_summary(best_vgg16_model, model_name=\"VGG16\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"xwgKin1wTWUy","metadata":{"id":"xwgKin1wTWUy"},"source":["ResNet-50"]},{"cell_type":"code","execution_count":null,"id":"da61EXjyRBQ2","metadata":{"id":"da61EXjyRBQ2"},"outputs":[],"source":["def build_resnet50(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(shape=input_shape)\n","\n","    x = layers.Rescaling(255.0, name=\"to_255\")(inputs)\n","    x = layers.Lambda(resnet50_preproc, name=\"resnet50_prep\")(x)\n","\n","    base = keras.applications.ResNet50(include_top=False,\n","                                       input_shape=input_shape,\n","                                       weights='imagenet')\n","    base.trainable = False\n","    x = layers.GlobalAveragePooling2D()(base.output)\n","    x = layers.Dense(256,activation='relu')(x)\n","    outputs = layers.Dense(num_classes,activation='softmax')(x)\n","\n","    return models.Model(base.input, outputs)"]},{"cell_type":"code","execution_count":null,"id":"zz3Pbq8ZRDu9","metadata":{"id":"zz3Pbq8ZRDu9"},"outputs":[],"source":["resnet_model = build_resnet50()\n","history_resnet, best_resnet_model_path = compile_and_fit(resnet_model, train_ds, val_ds,\n","                                 model_name=\"ResNet50_finetune\",\n","                                 epochs=20, lr=1e-3)"]},{"cell_type":"code","execution_count":null,"id":"l13ZRROV8xFx","metadata":{"id":"l13ZRROV8xFx"},"outputs":[],"source":["best_resnet_model = keras.models.load_model(best_resnet_model_path)\n","evaluate_model(best_resnet_model, test_ds, class_names, model_name=\"RESNET50\")"]},{"cell_type":"code","execution_count":null,"id":"o9cN_-RtKTPk","metadata":{"id":"o9cN_-RtKTPk"},"outputs":[],"source":["plot_training_curves(history_resnet, title='ResNet-50')"]},{"cell_type":"code","execution_count":null,"id":"bJQbjMGuKUhf","metadata":{"id":"bJQbjMGuKUhf"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# resnet_model.save(os.path.join(MODEL_DIR, f\"resnet50_{timestamp}.h5\"))\n","# save_model_summary(best_vgg16_model, model_name=\"RESNET50\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"t1UH4wIKTYqx","metadata":{"id":"t1UH4wIKTYqx"},"source":["InceptionV3"]},{"cell_type":"code","execution_count":null,"id":"2RYS99IuL4Kr","metadata":{"id":"2RYS99IuL4Kr"},"outputs":[],"source":["def build_inceptionv3_model(input_shape=(*IMAGE_SIZE, 3), num_classes=NUM_CLASSES):\n","\n","    inputs = layers.Input(shape=input_shape)\n","\n","    if input_shape[:2] != (299, 299):\n","        x = layers.Resizing(299, 299)(inputs)\n","    else:\n","        x = inputs\n","\n","    x = layers.Rescaling(255.0, name=\"to_255\")(x)\n","    x = layers.Lambda(inceptionv3_preproc, name=\"inception_prep\")(x)\n","\n","    base_model = InceptionV3(\n","        include_top=False,\n","        input_shape=(299, 299, 3),  # InceptionV3 expects 299x299\n","        weights='imagenet',\n","        pooling='avg'\n","    )\n","\n","    base_model.trainable = False\n","\n","    x = base_model(x, training=False)\n","\n","    x = layers.Dense(128, activation='relu')(x)\n","    x = layers.BatchNormalization()(x)\n","    x = layers.Dropout(0.5)(x)\n","\n","    outputs = layers.Dense(num_classes, activation='softmax')(x)\n","\n","    return models.Model(inputs, outputs)"]},{"cell_type":"code","execution_count":null,"id":"WmC-zyLYMA1T","metadata":{"id":"WmC-zyLYMA1T"},"outputs":[],"source":["inceptionv3_model = build_inceptionv3_model()\n","history_inceptionv3, best_inceptionv3_model_path = compile_and_fit(inceptionv3_model, train_ds, val_ds,\n","                                 model_name=\"InceptionV3_finetune\",\n","                                 epochs=20, lr=1e-4)"]},{"cell_type":"code","execution_count":null,"id":"yx8FpqJ7MduA","metadata":{"id":"yx8FpqJ7MduA"},"outputs":[],"source":["best_inceptionv3_model = keras.models.load_model(best_inceptionv3_model_path)\n","evaluate_model(best_inceptionv3_model, test_ds, class_names, model_name=\"INCEPTIONV3\")"]},{"cell_type":"code","execution_count":null,"id":"G16KfcDsMuBV","metadata":{"id":"G16KfcDsMuBV"},"outputs":[],"source":["plot_training_curves(history_inceptionv3, title='InecptioV3')"]},{"cell_type":"code","execution_count":null,"id":"UhQmRyDMMbAN","metadata":{"id":"UhQmRyDMMbAN"},"outputs":[],"source":["# use to save model and mdel description\n","# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","# inceptionv3_model.save(os.path.join(MODEL_DIR, f\"inceptionv3_{timestamp}.h5\"))\n","# save_model_summary(best_inceptionv3_model, model_name=\"INCEPTIONV3\", save_dir=os.path.join(MODEL_DIR, \"summaries\"))"]},{"cell_type":"markdown","id":"04eb0049","metadata":{"id":"04eb0049"},"source":["##### 6. Data Augmentation"]},{"cell_type":"code","execution_count":null,"id":"b0a67644","metadata":{"id":"b0a67644"},"outputs":[],"source":["# Configuration A\n","\n","data_augment = keras.Sequential([\n","    layers.RandomFlip('horizontal'),\n","    layers.RandomRotation(0.05),\n","    layers.RandomZoom(0.05)\n","])\n","\n","# Configuration B\n","\n","# data_augment = keras.Sequential([\n","#     layers.RandomBrightness(0.03),\n","#     layers.RandomContrast(0.03),\n","# ])\n","\n","aug_train_ds = train_ds.map(lambda x, y: (data_augment(x, training=True), y))"]},{"cell_type":"markdown","id":"8BsYezlvo-Rz","metadata":{"id":"8BsYezlvo-Rz"},"source":["Best CNN - CNN6"]},{"cell_type":"code","execution_count":null,"id":"_kwJsR-jRH6M","metadata":{"id":"_kwJsR-jRH6M"},"outputs":[],"source":["cnn6_aug = build_custom_cnn_6()\n","history_aug_cnn6, cnn6_aug_path = compile_and_fit(cnn6_aug, aug_train_ds, val_ds,\n","                                     model_name=\"Aug_CNN6\",\n","                                     epochs=30, lr=1e-3)"]},{"cell_type":"code","execution_count":null,"id":"n8yzpHxTFz6z","metadata":{"id":"n8yzpHxTFz6z"},"outputs":[],"source":["cnn6_aug_model = keras.models.load_model(cnn6_aug_path)\n","evaluate_model(cnn6_aug_model, test_ds, class_names, model_name=\"CNN6_aug\")"]},{"cell_type":"code","execution_count":null,"id":"1Hu3TMgy76zd","metadata":{"id":"1Hu3TMgy76zd"},"outputs":[],"source":["plot_training_curves(history_aug_cnn6, title='CNN6_aug')"]},{"cell_type":"markdown","id":"nd5mC2sGpB6y","metadata":{"id":"nd5mC2sGpB6y"},"source":["VGG16"]},{"cell_type":"code","execution_count":null,"id":"yAeX8BK7RJCD","metadata":{"id":"yAeX8BK7RJCD"},"outputs":[],"source":["vgg16_aug = build_vgg16()\n","history_aug_vgg16, vgg16_aug_path = compile_and_fit(vgg16_aug, aug_train_ds, val_ds,\n","                                  model_name=\"vgg16_aug\",\n","                                  epochs=20, lr=1e-3)"]},{"cell_type":"code","execution_count":null,"id":"O84xHcrm_4PO","metadata":{"id":"O84xHcrm_4PO"},"outputs":[],"source":["vgg16_aug_model = keras.models.load_model(vgg16_aug_path)\n","evaluate_model(vgg16_aug_model, test_ds, class_names, model_name=\"VGG16_aug\")"]},{"cell_type":"code","execution_count":null,"id":"RFAQVats_5D2","metadata":{"id":"RFAQVats_5D2"},"outputs":[],"source":["plot_training_curves(history_aug_vgg16, title='VGG16_aug')"]},{"cell_type":"markdown","id":"lFDdDVWopEIP","metadata":{"id":"lFDdDVWopEIP"},"source":["ResNet-50"]},{"cell_type":"code","execution_count":null,"id":"jqWCsdgKRJ_8","metadata":{"id":"jqWCsdgKRJ_8"},"outputs":[],"source":["resnet_aug = build_resnet50()\n","history_aug_resnet50, resnet50_aug_path = compile_and_fit(resnet_aug, aug_train_ds, val_ds,\n","                                     model_name=\"ResNet50_aug\",\n","                                     epochs=20, lr=1e-4)"]},{"cell_type":"code","execution_count":null,"id":"pRiKnNGfCNLZ","metadata":{"id":"pRiKnNGfCNLZ"},"outputs":[],"source":["resnet50_aug_model = keras.models.load_model(resnet50_aug_path)\n","evaluate_model(resnet50_aug_model, test_ds, class_names, model_name=\"RESNET50_aug\")"]},{"cell_type":"code","execution_count":null,"id":"SPnNoW26CN8d","metadata":{"id":"SPnNoW26CN8d"},"outputs":[],"source":["plot_training_curves(history_aug_resnet50, title='RESNET50_aug')"]},{"cell_type":"markdown","id":"7m50hao5pGDS","metadata":{"id":"7m50hao5pGDS"},"source":["InceptionV3"]},{"cell_type":"code","execution_count":null,"id":"Tqm0Y9UyMTus","metadata":{"id":"Tqm0Y9UyMTus"},"outputs":[],"source":["inceptionv3_aug = build_inceptionv3_model()\n","history_aug_inceptionv3, inceptionv3_model_path = compile_and_fit(inceptionv3_aug, aug_train_ds, val_ds,\n","                                 model_name=\"InceptionV3_aug\",\n","                                 epochs=20, lr=1e-4)"]},{"cell_type":"code","execution_count":null,"id":"A8VUjI5rDv-z","metadata":{"id":"A8VUjI5rDv-z"},"outputs":[],"source":["inceptionv3_aug_model = keras.models.load_model(inceptionv3_model_path)\n","evaluate_model(inceptionv3_aug_model, test_ds, class_names, model_name=\"INCEPTIONV3_aug\")"]},{"cell_type":"code","execution_count":null,"id":"luDQSIoRDwyV","metadata":{"id":"luDQSIoRDwyV"},"outputs":[],"source":["plot_training_curves(history_aug_inceptionv3, title='INCEPTIONV3_aug')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}