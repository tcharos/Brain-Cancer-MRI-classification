{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86a5252",
   "metadata": {},
   "source": [
    "##### 1. Utility Functions and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932351b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#############\n",
    "# Colab check\n",
    "#############\n",
    "\n",
    "def is_colab():\n",
    "    return 'google.colab' in sys.modules\n",
    "\n",
    "#############\n",
    "# Dataset splitting function\n",
    "#############\n",
    "\n",
    "def split_dataset(input_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    random.seed(seed)\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "\n",
    "    classes = [d.name for d in input_dir.iterdir() if d.is_dir()]\n",
    "\n",
    "    for cls in classes:\n",
    "        class_dir = input_dir / cls\n",
    "        images = list(class_dir.glob('*'))\n",
    "        random.shuffle(images)\n",
    "\n",
    "        n_total = len(images)\n",
    "        n_train = int(train_ratio * n_total)\n",
    "        n_val = int(val_ratio * n_total)\n",
    "\n",
    "        splits = {\n",
    "            'Training': images[:n_train],\n",
    "            'Validation': images[n_train:n_train + n_val],\n",
    "            'Testing': images[n_train + n_val:],\n",
    "        }\n",
    "\n",
    "        for split_name, split_files in splits.items():\n",
    "            split_path = output_dir / split_name / cls\n",
    "            split_path.mkdir(parents=True, exist_ok=True)\n",
    "            for f in split_files:\n",
    "                shutil.copy(f, split_path / f.name)\n",
    "\n",
    "#############\n",
    "# Model\n",
    "#############\n",
    "\n",
    "def compile_and_fit(model,\n",
    "                    train_data,\n",
    "                    val_data,\n",
    "                    model_name,\n",
    "                    epochs=20,\n",
    "                    lr=1e-3,\n",
    "                    checkpoint_dir='./checkpoints'):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    ckpt_path = os.path.join(\n",
    "        checkpoint_dir,\n",
    "        f\"{model_name}\" + \"_{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "    )\n",
    "    checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "        filepath=ckpt_path,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    early = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=val_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early, checkpoint_cb]\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "#############\n",
    "# Plot\n",
    "#############\n",
    "\n",
    "def plot_history(histories, titles):\n",
    "    for h, t in zip(histories, titles):\n",
    "        plt.plot(h.history['val_accuracy'], label=f'{t} val_acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#############\n",
    "# Grad-CAM Heatmaps\n",
    "#############\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [last_conv_layer.output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def display_gradcam(img_path, model, last_conv_layer_name):\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    orig = tf.keras.preprocessing.image.img_to_array(\n",
    "        tf.keras.preprocessing.image.load_img(img_path)\n",
    "    )\n",
    "    heatmap_resized = tf.image.resize(heatmap[..., tf.newaxis], IMAGE_SIZE).numpy()\n",
    "    heatmap_col = plt.cm.jet(heatmap_resized.squeeze())[...,:3]\n",
    "    superimposed = heatmap_col * 0.4 + orig/255.0\n",
    "\n",
    "    fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "    axs[0].imshow(orig.astype('uint8'))\n",
    "    axs[0].set_title('Original')\n",
    "    axs[1].imshow(heatmap, cmap='jet')\n",
    "    axs[1].set_title('Heatmap')\n",
    "    axs[2].imshow(superimposed)\n",
    "    axs[2].set_title('Overlay')\n",
    "    for ax in axs:\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f26de",
   "metadata": {},
   "source": [
    "##### 2. Setup & Environment check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_colab():\n",
    "    print(\"âœ… Running in Google Colab\")\n",
    "\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Install and configure Kaggle API\n",
    "    !pip install -q kaggle\n",
    "    !mkdir -p ~/.kaggle\n",
    "    !cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "    # Download dataset from Kaggle if not already present\n",
    "    if not os.path.exists(\"./data/brain_tumor_raw\"):\n",
    "        !kaggle datasets download -d orvile/brain-cancer-mri-dataset\n",
    "        !unzip -q brain-cancer-mri-dataset.zip -d ./data\n",
    "\n",
    "    # Set dataset paths\n",
    "    RAW_DATA_DIR = \"/content/drive/MyDrive/datasets/brain_tumor_raw\"\n",
    "    DATA_DIR = \"/content/drive/MyDrive/datasets/brain_tumor_split\"\n",
    "\n",
    "    # Only split if not already done\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, \"Training\")):\n",
    "        print(\"ðŸ“¦ Splitting raw dataset into Training/Validation/Testing...\")\n",
    "        split_dataset(RAW_DATA_DIR, DATA_DIR)\n",
    "    else:\n",
    "        print(\"âœ… Pre-split dataset already exists.\")\n",
    "else:\n",
    "    print(\"ðŸ’» Running locally on Mac\")\n",
    "    DATA_DIR = \"/Users/yourname/Projects/brain_tumor_split\"  # Replace with your path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d45d35",
   "metadata": {},
   "source": [
    "##### 3. xxxxxxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41004efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4\n",
    "DATA_DIR = './data/brain_tumor_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe2df76",
   "metadata": {},
   "source": [
    "##### 4. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd87089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training + validation from 'Training' directory using an 80/20 split\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR, 'Training'),\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR, 'Training'),\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Load the held-out test set from 'Testing' directory\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(DATA_DIR, 'Testing'),\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Prefetch for performance\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_ds  = test_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81213bf0",
   "metadata": {},
   "source": [
    "##### 5. Experiment A: Custom CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_custom_cnn_1(input_shape=(*IMAGE_SIZE,3), num_classes=NUM_CLASSES):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32,3,activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128,activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes,activation='softmax')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# A1\n",
    "cnn1 = build_custom_cnn_1()\n",
    "history1 = compile_and_fit(cnn1, train_ds, val_ds,\n",
    "                           model_name=\"CNN_variant1\",\n",
    "                           epochs=30, lr=1e-3)\n",
    "\n",
    "\n",
    "def build_custom_cnn_2(input_shape=(*IMAGE_SIZE,3), num_classes=NUM_CLASSES):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64,3,activation='relu')(inputs)\n",
    "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128,3,activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256,activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes,activation='softmax')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "cnn2 = build_custom_cnn_2()\n",
    "history2 = compile_and_fit(cnn2, train_ds, val_ds,\n",
    "                           model_name=\"CNN_variant2\",\n",
    "                           epochs=30, lr=5e-4)\n",
    "\n",
    "\n",
    "def build_custom_cnn_3(input_shape=(*IMAGE_SIZE,3), num_classes=NUM_CLASSES):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32,3,activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32,3,activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128,activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes,activation='softmax')(x)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "cnn3 = build_custom_cnn_3()\n",
    "history3 = compile_and_fit(cnn3, train_ds, val_ds,\n",
    "                           model_name=\"CNN_variant3\",\n",
    "                           epochs=30, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9f77f6",
   "metadata": {},
   "source": [
    "##### 6. Experiment B: Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324276da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16(input_shape=(*IMAGE_SIZE,3), num_classes=NUM_CLASSES):\n",
    "    base = keras.applications.VGG16(include_top=False,\n",
    "                                    input_shape=input_shape,\n",
    "                                    weights='imagenet')\n",
    "    base.trainable = False\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dense(256,activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes,activation='softmax')(x)\n",
    "    return models.Model(base.input, outputs)\n",
    "\n",
    "vgg_model = build_vgg16()\n",
    "history_vgg = compile_and_fit(vgg_model, train_ds, val_ds,\n",
    "                              model_name=\"VGG16_finetune\",\n",
    "                              epochs=15, lr=1e-4)\n",
    "\n",
    "\n",
    "def build_resnet50(input_shape=(*IMAGE_SIZE,3), num_classes=NUM_CLASSES):\n",
    "    base = keras.applications.ResNet50(include_top=False,\n",
    "                                       input_shape=input_shape,\n",
    "                                       weights='imagenet')\n",
    "    base.trainable = False\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dense(256,activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes,activation='softmax')(x)\n",
    "    return models.Model(base.input, outputs)\n",
    "\n",
    "resnet_model = build_resnet50()\n",
    "history_resnet = compile_and_fit(resnet_model, train_ds, val_ds,\n",
    "                                 model_name=\"ResNet50_finetune\",\n",
    "                                 epochs=15, lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb0049",
   "metadata": {},
   "source": [
    "##### 7. Experiment C: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a67644",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augment = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "aug_train_ds = train_ds.map(lambda x, y: (data_augment(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# C1\n",
    "best_cnn_aug = build_custom_cnn_1()\n",
    "history_aug_custom = compile_and_fit(best_cnn_aug, aug_train_ds, val_ds,\n",
    "                                     model_name=\"Aug_CNN_best\",\n",
    "                                     epochs=30, lr=1e-3)\n",
    "\n",
    "# C2\n",
    "aug_vgg = build_vgg16()\n",
    "history_aug_vgg = compile_and_fit(aug_vgg, aug_train_ds, val_ds,\n",
    "                                  model_name=\"Aug_VGG16\",\n",
    "                                  epochs=15, lr=1e-4)\n",
    "\n",
    "# C3\n",
    "aug_resnet = build_resnet50()\n",
    "history_aug_resnet = compile_and_fit(aug_resnet, aug_train_ds, val_ds,\n",
    "                                     model_name=\"Aug_ResNet50\",\n",
    "                                     epochs=15, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808728e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best models on test set\n",
    "for name, model in [\n",
    "    (\"Best_Custom_CNN\", best_custom_cnn),\n",
    "    (\"VGG16\", vgg_model),\n",
    "    (\"ResNet50\", resnet_model)\n",
    "]:\n",
    "    loss, acc = model.evaluate(test_ds)\n",
    "    print(f\"{name} test accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029a35a",
   "metadata": {},
   "source": [
    "##### 8. Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(\n",
    "    [history1, history2, history3,\n",
    "     history_vgg, history_resnet,\n",
    "     history_aug_custom, history_aug_vgg, history_aug_resnet],\n",
    "    ['CNN1','CNN2','CNN3','VGG','ResNet',\n",
    "     'Aug-CNN','Aug-VGG','Aug-ResNet'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
